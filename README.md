# ğŸŒ WebCrawler

A powerful web crawler designed to scrape e-commerce websites and extract valuable data such as product prices, images, sellers, and more.

---

## ğŸš€ Features

âœ… Crawl e-commerce websites to gather product information.  
âœ… Extract product details like prices, images, and seller information.  
âœ… Store extracted data in a PostgreSQL database.  
âœ… Optimized for efficiency and scalability.

---

## ğŸ› ï¸ Requirements

- **Python 3.x**
- **Scrapy Framework**
- **PostgreSQL**
- **Docker (Optional, for containerized deployment)**

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/ParsaMehdipour/WebCrawler.git
cd WebCrawler
```

### 2ï¸âƒ£ Set Up a Virtual Environment
```bash
python -m venv venv
```

### 3ï¸âƒ£ Activate the Virtual Environment
- On **Linux/macOS**:
  ```bash
  source venv/bin/activate
  ```
- On **Windows**:
  ```bash
  venv\Scripts\activate
  ```

### 4ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

### ğŸ›¢ï¸ PostgreSQL Setup
1. Ensure PostgreSQL is installed and running.
2. Create a database and user for the application.

### ğŸ”§ Database Connection Configuration
Modify the connection settings in the code:
```python
self.connection = psycopg2.connect(
    host='localhost',
    user='your_username',
    password='your_password',
    database='your_database'
)
```

---

## ğŸš´ Usage

### ğŸ³ Running with Docker
#### 1ï¸âƒ£ Build the Docker image
```bash
docker build -t webcrawler .
```

#### 2ï¸âƒ£ Run the Docker container
```bash
docker-compose up
```

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

Contributions are welcome! If you find any bugs or have feature requests, please open an issue or submit a pull request. ğŸš€

ğŸ¯ Happy Crawling! ğŸ•·ï¸

